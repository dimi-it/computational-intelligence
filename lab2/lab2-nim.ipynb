{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Copyright **`(c)`** 2022 Giovanni Squillero `<squillero@polito.it>`  \n",
    "[`https://github.com/squillero/computational-intelligence`](https://github.com/squillero/computational-intelligence)  \n",
    "Free for personal or classroom use; see [`LICENSE.md`](https://github.com/squillero/computational-intelligence/blob/master/LICENSE.md) for details.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Lab 3: ES\n",
    "\n",
    "## Task\n",
    "\n",
    "Write agents able to play [*Nim*](https://en.wikipedia.org/wiki/Nim), with an arbitrary number of rows and an upper bound $k$ on the number of objects that can be removed in a turn (a.k.a., *subtraction game*).\n",
    "\n",
    "The goal of the game is to **avoid** taking the last object.\n",
    "\n",
    "* Task2.1: An agent using fixed rules based on *nim-sum* (i.e., an *expert system*)\n",
    "* Task2.2: An agent using evolved rules using ES\n",
    "\n",
    "## Instructions\n",
    "\n",
    "* Create the directory `lab2` inside your personal course repository for the course \n",
    "* Put a `README.md` and your solution (all the files, code and auxiliary data if needed)\n",
    "\n",
    "## Notes\n",
    "\n",
    "* Working in group is not only allowed, but recommended (see: [Ubuntu](https://en.wikipedia.org/wiki/Ubuntu_philosophy) and [Cooperative Learning](https://files.eric.ed.gov/fulltext/EJ1096789.pdf)). Collaborations must be explicitly declared in the `README.md`.\n",
    "* [Yanking](https://www.emacswiki.org/emacs/KillingAndYanking) from the internet is allowed, but sources must be explicitly declared in the `README.md`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pprint import pprint, pformat\n",
    "from collections import namedtuple\n",
    "import random\n",
    "from copy import deepcopy, copy\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The *Nim* and *Nimply* classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nimply = namedtuple(\"Nimply\", \"row, num_objects\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nim:\n",
    "    def __init__(self, num_rows: int, k: int = None) -> None:\n",
    "        self._rows = [i * 2 + 1 for i in range(num_rows)]\n",
    "        self._k = k\n",
    "\n",
    "    def __bool__(self):\n",
    "        return sum(self._rows) > 0\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<\" + \" \".join(str(_) for _ in self._rows) + \">\"\n",
    "\n",
    "    @property\n",
    "    def rows(self) -> tuple:\n",
    "        return tuple(self._rows)\n",
    "\n",
    "    def nimming(self, ply: Nimply) -> None:\n",
    "        row, num_objects = ply\n",
    "        assert self._rows[row] >= num_objects\n",
    "        assert self._k is None or num_objects <= self._k\n",
    "        self._rows[row] -= num_objects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Match\n",
    "The match class is used to define one or more match between different strategies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Match:\n",
    "    def __init__(self, num_rows, player0, player1, verbose=False):\n",
    "        self.nim = Nim(num_rows)\n",
    "        self.strategies = (player0, player1)\n",
    "        if verbose:\n",
    "            logging.getLogger().setLevel(logging.DEBUG)\n",
    "        else:\n",
    "            logging.getLogger().setLevel(logging.INFO)\n",
    "        \n",
    "    def play(self, no_mark=False, starting_player=0):\n",
    "        if no_mark:\n",
    "            nim = deepcopy(self.nim)\n",
    "        else:\n",
    "             nim = self.nim\n",
    "        player = starting_player\n",
    "        logging.debug(f\"init : {nim}\")\n",
    "        while nim:\n",
    "            ply = self.strategies[player](nim)\n",
    "            logging.debug(f\"ply: player {player} plays {ply}\")\n",
    "            nim.nimming(ply)\n",
    "            logging.debug(f\"status: {nim}\")\n",
    "            player = 1 - player\n",
    "        logging.debug(f\"status: Player {player} won!\")  \n",
    "        return player\n",
    "        \n",
    "    def play_n(self, n_matches, change_starting_player=True):\n",
    "        player0_win = 0\n",
    "        player1_win = 0\n",
    "        for i in range(n_matches):\n",
    "            w = self.play(no_mark=True, starting_player=i%2 if change_starting_player else 0)\n",
    "            if w == 0:\n",
    "                player0_win += 1\n",
    "            else:\n",
    "                player1_win += 1\n",
    "        logging.debug(f\"Player 0 won {player0_win} times\") \n",
    "        logging.debug(f\"Player 1 won {player1_win} times\")\n",
    "        return player0_win, player1_win"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sample (and silly) startegies "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def pure_random(state: Nim) -> Nimply:\n",
    "    \"\"\"A completely random move\"\"\"\n",
    "    row = random.choice([r for r, c in enumerate(state.rows) if c > 0])\n",
    "    num_objects = random.randint(1, state.rows[row])\n",
    "    return Nimply(row, num_objects)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def gabriele(state: Nim) -> Nimply:\n",
    "    \"\"\"Pick always the maximum possible number of the lowest row\"\"\"\n",
    "    possible_moves = [(r, o) for r, c in enumerate(state.rows) for o in range(1, c + 1)]\n",
    "    return Nimply(*max(possible_moves, key=lambda m: (-m[0], m[1])))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def adaptive(state: Nim) -> Nimply:\n",
    "    \"\"\"A strategy that can adapt its parameters\"\"\"\n",
    "    genome = {\"love_small\": 0.5}\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def nim_sum(state: Nim) -> int:\n",
    "    tmp = np.array([tuple(int(x) for x in f\"{c:032b}\") for c in state.rows])\n",
    "    xor = tmp.sum(axis=0) % 2\n",
    "    return int(\"\".join(str(_) for _ in xor), base=2)\n",
    "\n",
    "\n",
    "def analize(raw: Nim) -> dict:\n",
    "    cooked = dict()\n",
    "    cooked[\"possible_moves\"] = dict()\n",
    "    for ply in (Nimply(r, o) for r, c in enumerate(raw.rows) for o in range(1, c + 1)):\n",
    "        tmp = deepcopy(raw)\n",
    "        tmp.nimming(ply)\n",
    "        cooked[\"possible_moves\"][ply] = nim_sum(tmp)\n",
    "    return cooked\n",
    "\n",
    "\n",
    "def optimal(state: Nim) -> Nimply:\n",
    "    analysis = analize(state)\n",
    "    # logging.debug(f\"analysis:\\n{pformat(analysis)}\")\n",
    "    spicy_moves = [ply for ply, ns in analysis[\"possible_moves\"].items() if ns != 0]\n",
    "    if not spicy_moves:\n",
    "        spicy_moves = list(analysis[\"possible_moves\"].keys())\n",
    "    ply = random.choice(spicy_moves)\n",
    "    return ply"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Expert agent (Task2.1)\n",
    "### a.k.a. Real Optimal\n",
    "An agent using fixed rules based on *nim-sum* that is the real optimal and always win"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def real_optimal(state: Nim) -> Nimply:\n",
    "    rows_with_more_than_two = [id for id, dim in enumerate(state.rows) if dim>=2]\n",
    "    if len(rows_with_more_than_two) == 1:\n",
    "        rows_with_one = len([None for dim in state.rows if dim==1])\n",
    "        row_id = rows_with_more_than_two[0]\n",
    "        if rows_with_one%2 == 0:\n",
    "            return Nimply(row_id, state.rows[row_id] - 1)\n",
    "        else:\n",
    "            return Nimply(row_id, state.rows[row_id])\n",
    "    else:\n",
    "        analysis = analize(state)\n",
    "        logging.debug(f\"analysis:\\n{pformat(analysis)}\")\n",
    "        spicy_moves = [ply for ply, ns in analysis[\"possible_moves\"].items() if ns == 0]\n",
    "        if not spicy_moves:\n",
    "            spicy_moves = list(analysis[\"possible_moves\"].keys())\n",
    "        ply = random.choice(spicy_moves)\n",
    "        return ply"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ES (Task2.2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Rules\n",
    "List of 6 rules that the Evolutionary Strategy will try to select based on an evolving probability."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "########Util###########\n",
    "def min_id_of_list(my_list, non_zero=False):\n",
    "    if non_zero:\n",
    "        lower = 0\n",
    "        id = 0\n",
    "        for i, val in enumerate(my_list):\n",
    "            if (val < lower and val != 0) or lower == 0:\n",
    "                lower = val\n",
    "                id = i\n",
    "        return  id\n",
    "    else:\n",
    "        return min(range(len(my_list)), key=my_list.__getitem__)\n",
    "\n",
    "def max_id_of_list(my_list):\n",
    "    return max(range(len(my_list)), key=my_list.__getitem__)\n",
    "#######################\n",
    "\n",
    "\n",
    "def empty_lower(state: Nim) ->Nimply:\n",
    "    index = min_id_of_list(state.rows, non_zero=True)\n",
    "    return Nimply(index, state.rows[index])\n",
    "        \n",
    "def empty_greater(state: Nim) ->Nimply:\n",
    "    index = max_id_of_list(state.rows)\n",
    "    return Nimply(index, state.rows[index])\n",
    "\n",
    "def leave_one_to_lower(state: Nim) ->Nimply | None:\n",
    "    index = min_id_of_list(state.rows, non_zero=True)\n",
    "    if state.rows[index] == 1:\n",
    "        return None\n",
    "    return Nimply(index, state.rows[index] - 1)\n",
    "def leave_one_to_greater(state: Nim) ->Nimply | None:\n",
    "    index = max_id_of_list(state.rows)\n",
    "    if state.rows[index] == 1:\n",
    "        return None\n",
    "    return Nimply(index, state.rows[index] - 1)\n",
    "\n",
    "def remove_one_to_lower(state: Nim) ->Nimply:\n",
    "    index = min_id_of_list(state.rows, non_zero=True)\n",
    "    return Nimply(index, 1)\n",
    "\n",
    "def remove_one_to_greater(state: Nim) ->Nimply:\n",
    "    index = max_id_of_list(state.rows)\n",
    "    return Nimply(index, 1)\n",
    "\n",
    "\n",
    "rules = [empty_lower, empty_greater, leave_one_to_lower, leave_one_to_greater, remove_one_to_lower, remove_one_to_greater]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Agent that play the game, based on a list of probability"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, rules_probability, rules):\n",
    "        self.rules_probability = rules_probability / sum(rules_probability)\n",
    "        self.rules = rules\n",
    "        \n",
    "    def move(self, state: Nim) -> Nimply:\n",
    "        #Every move a list of rules, ordered based on the evolute probability, are extracted and are applied until one of them give a valid result.\n",
    "        rules_ordered = np.random.choice(self.rules, len(self.rules), replace=False, p=self.rules_probability)\n",
    "        for rule in rules_ordered:\n",
    "            out = rule(state)\n",
    "            if out is not None:\n",
    "                return out"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Fitness function to evaluate the agent against a list of opponents"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "opponents = [gabriele, pure_random, optimal]\n",
    "match_per_opponents = 15\n",
    "row_count = 5\n",
    "\n",
    "def fitness(agent):\n",
    "    agent_win = 0\n",
    "    for opponent in opponents:\n",
    "        match = Match(row_count, agent.move, opponent)\n",
    "        win_0, _ = match.play_n(match_per_opponents)\n",
    "        agent_win += win_0\n",
    "    return agent_win / (match_per_opponents * len(opponents))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Adaptive (μ,λ)-ES"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "population_len = 15 #u\n",
    "offspring_len = 100 #lambda\n",
    "mu = 0.5\n",
    "dimensions = len(rules) + 1\n",
    "generations = 200 #1_000_000 // offspring_len\n",
    "\n",
    "population = np.random.random((population_len, dimensions))\n",
    "best_fitness = None\n",
    "best_offspring = None\n",
    "history = list()\n",
    "\n",
    "for gen in tqdm(range(generations)):\n",
    "    offspring = population[np.random.randint(0, population_len, size=(offspring_len, ))]\n",
    "    \n",
    "    #mutate mu\n",
    "    offspring[:, -1] = np.random.normal(\n",
    "            loc=offspring[:, -1], scale=0.2\n",
    "        )\n",
    "    #clamp the value of mu at 1e-5 (value of mu to low are not useful because lead to no mutation)\n",
    "    offspring[offspring[:, -1] < 1e-5, -1] = 1e-5\n",
    "    \n",
    "    #mutate values\n",
    "    offspring[:, 0:-1] = np.random.normal(\n",
    "            loc=offspring[:, 0:-1], scale=offspring[:, -1].reshape(-1, 1)\n",
    "        )\n",
    "    #clamp the value of the values at 1e-5 (values lower than 0 are not valid probability)\n",
    "    offspring[offspring < 1e-5] = 1e-5\n",
    "    \n",
    "    fit = np.array([fitness(Agent(offspring[i, 0:-1], rules)) for i in range(population_len)])\n",
    "    offspring = offspring[fit.argsort()]\n",
    "    \n",
    "    if best_fitness is None or best_fitness < np.max(fit):\n",
    "            best_fitness = np.max(fit)\n",
    "            best_offspring = offspring[0,:-1]\n",
    "            history.append((gen, best_fitness))\n",
    "    population = np.copy(offspring[-population_len:])\n",
    "    \n",
    "logging.info(\n",
    "    f\"Best solution: {history[len(history) - 1][1]}\"\n",
    ")\n",
    "\n",
    "history = np.array(history[:-1])\n",
    "plt.figure(figsize=(14, 4))\n",
    "plt.plot(history[:, 0], history[:, 1], marker=\".\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Result\n",
    "### The result of the agent based on the evolutionary strategy is a 82.2% of win rate against the three standard opponent (gabriele, pure_random, optimal)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('ci22-dPIXJ0_o-py3.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "10197e8e2f2aa67e2c349105091c77f4cd384fce4877865f002d9ec653f96bc0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
